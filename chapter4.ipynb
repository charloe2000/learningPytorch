{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Notes in Chapter 4\n",
    "1. PyTorch modules dealing with image data require tensors to be laid out as C × H × W :\n",
    "channels, height, and width, respectively.\n",
    "2. Sometimes images have an alpha channel, in other words, they have 4 channel.\n",
    "3. Neural networks usually work with floating-point tensors as their input.\n",
    "4. Neural networks exhibit the best training performance when the input data ranges roughly from 0 to 1, or from -1 to 1 (this is an effect of how their building blocks are defined).\n",
    "5. In working with images, it is good practice to compute the mean and standard deviation on all the training data in advance and then subtract and divide by these fixed, precomputed quantities.\n",
    "6. Calling `view` on a tensor returns a new tensor that changes the number of dimensions and the striding information, without changing the storage."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(180, 254, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "# img_arr is numpy arr\n",
    "img_arr = imageio.imread('data/ch4/bobby.jpg')\n",
    "# (height, width, channel), (H, W, C)\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 180, 254])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# img is torch tensor\n",
    "img = torch.from_numpy(img_arr)\n",
    "# (channel, height, width), (C, H ,W)\n",
    "out = img.permute(2, 0, 1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"data/ch4/image-cats\"\n",
    "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.png']\n",
    "for i, filename in enumerate(filenames):\n",
    "    # numpy array of img\n",
    "    img_t = imageio.imread(os.path.join(data_dir, filename))\n",
    "    # torch tensor, but (H, W, C)\n",
    "    img_t = torch.from_numpy(img_t)\n",
    "    # permute to (C, H, W)\n",
    "    img_t = img_t.permute(2, 0, 1)\n",
    "    # sometime images have an alpha channel, we just need RGB channels.\n",
    "    img_t = img_t[:3]\n",
    "    batch[i] = img_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize tensor to 0~1\n",
    "batch  = batch.float()\n",
    "# Apporoach One: simply divide by 255.0\n",
    "batch /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "batch[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apporoach Two:\n",
    "# compute the mean and standard deviation of the input data and scale it\n",
    "# so that the output has zero mean and unit standard deviation across each channel:\n",
    "n_channels = batch.shape[1]\n",
    "for c in range(n_channels):\n",
    "    # mean and std is a scalar\n",
    "    mean = torch.mean(batch[:, c])\n",
    "    std = torch.std(batch[:, c])\n",
    "    batch[:, c] = (batch[:, c] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading DICOM (examining files): 1/99 files (1.0%99/99 files (100.0%)\n",
      "  Found 1 correct series.\n",
      "Reading DICOM (loading data): 56/99  (56.699/99  (100.0%)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(99, 512, 512)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "dir_path = 'data/ch4/volumetric-dicom/2-LUNG 3.0  B70f-04083'\n",
    "vol_arr = imageio.volread(dir_path, 'DICOM')\n",
    "vol_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 99, 512, 512])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import torch\n",
    "vol = torch.from_numpy(vol_arr).float()\n",
    "vol = torch.unsqueeze(vol, 0)\n",
    "vol.shape"
   ]
  },
  {
   "source": [
    "## 4.3 Representing tabular data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4898, 12)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "wine_path = 'data/ch4/tabular-wine/winequality-white.csv'\n",
    "wineq_np = np.loadtxt(wine_path, dtype=np.float32, delimiter=';', skiprows=1)\n",
    "wineq_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['fixed acidity',\n",
       " 'volatile acidity',\n",
       " 'citric acid',\n",
       " 'residual sugar',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'total sulfur dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol',\n",
       " 'quality']"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "import csv\n",
    "# check all the columns have been read\n",
    "col_list = next(csv.reader(open(wine_path), delimiter=';'))\n",
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([4898, 12]), torch.float32)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "wineq = torch.from_numpy(wineq_np)\n",
    "wineq.shape, wineq.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4898, 11])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "data = wineq[:, :-1]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4898])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "target = wineq[:, -1].long()\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "target_onehot = torch.zeros(target.shape[0], 10)\n",
    "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)\n",
    "target_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
       "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "data_mean = torch.mean(data, dim=0)\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([7.1211e-01, 1.0160e-02, 1.4646e-02, 2.5726e+01, 4.7733e-04, 2.8924e+02,\n",
       "        1.8061e+03, 8.9455e-06, 2.2801e-02, 1.3025e-02, 1.5144e+00])"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "data_var = torch.var(data, dim=0)\n",
    "data_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 1.7208e-01, -8.1761e-02,  2.1326e-01,  ..., -1.2468e+00,\n",
       "         -3.4915e-01, -1.3930e+00],\n",
       "        [-6.5743e-01,  2.1587e-01,  4.7996e-02,  ...,  7.3995e-01,\n",
       "          1.3422e-03, -8.2419e-01],\n",
       "        [ 1.4756e+00,  1.7450e-02,  5.4378e-01,  ...,  4.7505e-01,\n",
       "         -4.3677e-01, -3.3663e-01],\n",
       "        ...,\n",
       "        [-4.2043e-01, -3.7940e-01, -1.1915e+00,  ..., -1.3130e+00,\n",
       "         -2.6153e-01, -9.0545e-01],\n",
       "        [-1.6054e+00,  1.1666e-01, -2.8253e-01,  ...,  1.0049e+00,\n",
       "         -9.6251e-01,  1.8574e+00],\n",
       "        [-1.0129e+00, -6.7703e-01,  3.7852e-01,  ...,  4.7505e-01,\n",
       "         -1.4882e+00,  1.0448e+00]])"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "data_norm = (data - data_mean) / torch.sqrt(data_var)\n",
    "data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(20))"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "bad_indexes = target <= 3\n",
    "bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([20, 11])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "bad_target = data[bad_indexes]\n",
    "bad_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 0 fixed acidity          7.60   6.89   6.73\n 1 volatile acidity       0.33   0.28   0.27\n 2 citric acid            0.34   0.34   0.33\n 3 residual sugar         6.39   6.71   5.26\n 4 chlorides              0.05   0.05   0.04\n 5 free sulfur dioxide   53.33  35.42  34.55\n 6 total sulfur dioxide 170.60 141.83 125.25\n 7 density                0.99   0.99   0.99\n 8 pH                     3.19   3.18   3.22\n 9 sulphates              0.47   0.49   0.50\n10 alcohol               10.34  10.26  11.42\n"
     ]
    }
   ],
   "source": [
    "# get information about wine grouped into bad, middle, good categories\n",
    "bad_data = data[target <= 3]\n",
    "mid_data = data[(target > 3) & (target < 7)]\n",
    "good_data = data[(target >= 7)]\n",
    "\n",
    "bad_mean = torch.mean(bad_data, dim=0)\n",
    "mid_mean = torch.mean(mid_data, dim=0)\n",
    "good_mean = torch.mean(good_data, dim=0)\n",
    "\n",
    "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):\n",
    "    print('{:2} {:20} {:6.2f} {:6.2f} {:6.2f}'.format(i, *args))"
   ]
  },
  {
   "source": [
    "The bad wines seem to have higher sulfur dioxide, so we use a threshold on total sulfur dioxide to discriminating good wines from bad wines."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([4898]), tensor(2727))"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "total_sulfur_threshold = 141.83\n",
    "total_sulfur_data = data[:, 6]\n",
    "predicted_indexes = total_sulfur_data < total_sulfur_threshold\n",
    "predicted_indexes.shape, predicted_indexes.sum()"
   ]
  },
  {
   "source": [
    "This means that we predict there are 2727 good wines in 4898 wines just by total sulfur threshold."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([4898]), tensor(3258))"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "actual_indexes = target > 5\n",
    "actual_indexes.shape, actual_indexes.sum()"
   ]
  },
  {
   "source": [
    "Actually, there are 3258 good wines in 4898 wines."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor(2018), tensor(0.7400), tensor(0.6194))"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "n_matches = torch.sum(predicted_indexes & actual_indexes)\n",
    "n_predicted = torch.sum(predicted_indexes)\n",
    "n_actual = torch.sum(actual_indexes)\n",
    "n_matches, n_matches / n_predicted, n_matches / n_actual"
   ]
  },
  {
   "source": [
    "We got 2018 wines right. Since we predicted 2,700 wines, this gives us a 74% chance that if we predict a wine to be high quality, it actually is.  Unfortunately, there are 3,200 good wines, and we only identified 61% of them."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 4.4 Working with time series"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([17520, 17])"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "bikes_path = 'data/ch4/bike-sharing-dataset/hour-fixed.csv'\n",
    "bikes_np = np.loadtxt(bikes_path, dtype=np.float, delimiter=',', \n",
    "    skiprows=1, converters={1: lambda x: float(x[8:10])})\n",
    "bikes = torch.from_numpy(bikes_np)\n",
    "bikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(['instant',\n",
       "  'dteday',\n",
       "  'season',\n",
       "  'yr',\n",
       "  'mnth',\n",
       "  'hr',\n",
       "  'holiday',\n",
       "  'weekday',\n",
       "  'workingday',\n",
       "  'weathersit',\n",
       "  'temp',\n",
       "  'atemp',\n",
       "  'hum',\n",
       "  'windspeed',\n",
       "  'casual',\n",
       "  'registered',\n",
       "  'cnt'],\n",
       " 17)"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "bikes_col_list = next(csv.reader(open(bikes_path), delimiter=','))\n",
    "bikes_col_list, len(bikes_col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([730, 24, 17])"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "daily_bikes = bikes.view(-1, 24, bikes.shape[1])\n",
    "daily_bikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([730, 17, 24])"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "daily_bikes = daily_bikes.transpose(1, 2)\n",
    "# (N, C, L)\n",
    "daily_bikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "# for simplify, we focus on one day of 24 hours\n",
    "first_day = bikes[:24].long()\n",
    "weather_onehot = torch.zeros(first_day.shape[0], 4)\n",
    "weather_onehot.scatter_(dim=1, index=first_day[:, 9].unsqueeze(-1)-1, value=1.0)\n",
    "weather_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  6.0000,\n",
       "          0.0000,  1.0000,  0.2400,  0.2879,  0.8100,  0.0000,  3.0000, 13.0000,\n",
       "         16.0000,  1.0000,  0.0000,  0.0000,  0.0000]], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "torch.cat((bikes[:24], weather_onehot), dim=1)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "daily_weather_onehot = torch.zeros(daily_bikes.shape[0], 4, daily_bikes.shape[2])\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "daily_weather_onehot.scatter_(dim=1, index=daily_bikes[:, 9, :].unsqueeze(1).long()-1, value=1.0)\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([730, 25, 24])"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "daily_bikes = torch.cat((daily_bikes, daily_weather_onehot), dim=1)\n",
    "daily_bikes.shape"
   ]
  },
  {
   "source": [
    "## 4.5 Representing text"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/ch4/jane-austen/1342-0.txt', encoding='utf8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'“Impossible, Mr. Bennet, impossible, when I am not acquainted with him'"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "lines = text.split('\\n')\n",
    "line = lines[200]\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([70, 128])"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "letter_t = torch.zeros(len(line), 128)\n",
    "letter_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot encode letter\n",
    "for i, letter in enumerate(line.lower().strip()):\n",
    "    letter_index = ord(letter) if ord(letter) < 128 else 0\n",
    "    letter_t[i][letter_index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('“Impossible, Mr. Bennet, impossible, when I am not acquainted with him',\n",
       " ['impossible',\n",
       "  'mr',\n",
       "  'bennet',\n",
       "  'impossible',\n",
       "  'when',\n",
       "  'i',\n",
       "  'am',\n",
       "  'not',\n",
       "  'acquainted',\n",
       "  'with',\n",
       "  'him'])"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "def clean_words(input_str):\n",
    "    punctuation = '.,;:\"!?“”_-'\n",
    "    word_list = input_str.lower().replace('\\n', ' ').split()\n",
    "    word_list = [word.strip(punctuation) for word in word_list]\n",
    "    return word_list\n",
    "\n",
    "words_in_line = clean_words(line)\n",
    "line, words_in_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7261, 3394)"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "# build word:index dictionary\n",
    "word_list = sorted(set(clean_words(text)))\n",
    "word2index_dict = {word: i for (i, word) in enumerate(word_list)}\n",
    "\n",
    "len(word2index_dict), word2index_dict['impossible']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 0 3394 impossible\n 1 4305 mr\n 2  813 bennet\n 3 3394 impossible\n 4 7078 when\n 5 3315 i\n 6  415 am\n 7 4436 not\n 8  239 acquainted\n 9 7148 with\n10 3215 him\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([11, 7261])"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "word_t = torch.zeros(len(words_in_line), len(word2index_dict))\n",
    "for i, word in enumerate(words_in_line):\n",
    "    word_index = word2index_dict[word]\n",
    "    word_t[i][word_index] = 1\n",
    "    print('{:2} {:4} {}'.format(i, word_index, word))\n",
    "\n",
    "word_t.shape"
   ]
  },
  {
   "source": [
    "## Exercise"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 180, 254])"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "# exercise 1.a\n",
    "img_np = imageio.imread('data/ch4/bobby.jpg')\n",
    "img_t = torch.from_numpy(img_np).float()\n",
    "img_t = img_t.permute(2, 0, 1)\n",
    "img_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([180, 254])"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "# exercise 1.b\n",
    "img_mean = torch.mean(img_t, dim=0)\n",
    "img_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([3]), tensor([149.9068, 112.7613,  71.0230]))"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "# exercise 1.c\n",
    "img_mean_channel = torch.mean(img_t.view(3, -1), dim=1)\n",
    "img_mean_channel.shape, img_mean_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1152"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "# exercise 2.a\n",
    "with open('data/ch4/bike-sharing-dataset/fix_missing_hours.py') as f:\n",
    "    code_text = f.read()\n",
    "\n",
    "len(code_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(87, 57)"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "code_words = code_text.lower().replace(r\"[a-z]\", ' ').split()\n",
    "code_word_list = sorted(set(code_words))\n",
    "len(code_words), len(code_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 0 29 import\n 1 12 copy\n 2 29 import\n 3 15 csv\n 4  0 #\n 5 31 instant,dteday,season,yr,mnth,hr,holiday,weekday,workingday,weathersit,temp,atemp,hum,windspeed,casual,registered,cnt\n 6 56 with\n 7 48 open('hour.csv',\n 8 44 newline='')\n 9 11 as\n10 27 hour_file,\n11 47 open('hour-fixed.csv',\n12  3 'w',\n13 44 newline='')\n14 11 as\n15 23 fixed_file:\n16 25 hour_csv\n17  9 =\n18 16 csv.reader(hour_file)\n19 20 fixed_csv\n20  9 =\n21 17 csv.writer(fixed_file)\n22 37 last_row\n23  9 =\n24 45 none\n25 24 for\n26 55 this_row\n27 30 in\n28 26 hour_csv:\n29 28 if\n30 37 last_row\n31 34 is\n32 46 none:\n33 49 pass\n34 18 elif\n35 38 last_row[0]\n36 10 ==\n37  2 'instant':\n38 49 pass\n39 19 else:\n40 35 last_hour\n41  9 =\n42 32 int(last_row[5])\n43 52 this_hour\n44  9 =\n45 33 int(this_row[5])\n46 28 if\n47 52 this_hour\n48  8 <\n49 36 last_hour:\n50 52 this_hour\n51  4 +=\n52  6 24\n53 40 missing_row\n54  9 =\n55 13 copy.deepcopy(last_row)\n56 42 missing_row[-1]\n57  9 =\n58  5 0\n59 24 for\n60 39 missing_hour\n61 30 in\n62 51 range(last_hour+1,\n63 53 this_hour):\n64 28 if\n65 39 missing_hour\n66 10 ==\n67  7 24:\n68 40 missing_row\n69  9 =\n70 14 copy.deepcopy(this_row)\n71 42 missing_row[-1]\n72  9 =\n73  5 0\n74 43 missing_row[5]\n75  9 =\n76 39 missing_hour\n77  1 %\n78  6 24\n79 21 fixed_csv.writerow(missing_row)\n80 50 print(last_hour,\n81 54 this_hour,\n82 41 missing_row)\n83 22 fixed_csv.writerow(this_row)\n84 37 last_row\n85  9 =\n86 55 this_row\n"
     ]
    }
   ],
   "source": [
    "code_word2index_dict = {code_word:i for i, code_word in enumerate(code_word_list)}\n",
    "\n",
    "code_word_onehot = torch.zeros(len(code_words), len(code_word_list))\n",
    "for i, code_word in enumerate(code_words):\n",
    "    code_word_index = code_word2index_dict[code_word]\n",
    "    code_word_onehot[i][code_word_index] = 1\n",
    "\n",
    "    print('{:2} {:2} {}'.format(i, code_word_index, code_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}